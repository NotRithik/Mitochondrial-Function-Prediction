{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "First, create a graph representation of the information we have. \n",
    "This would be information about the elements, and the nodes. \n",
    "Using this, we will feed it into our SVM, or a Random Forest, and see from there onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import ast\n",
    "import io\n",
    "\n",
    "\n",
    "# Set up torch to use CUDA or MPS if either are available\n",
    "device = torch.device('cuda:0')  if torch.cuda.is_available() else torch.device('mps:0') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "torch.set_default_device(device)\n",
    "\n",
    "USE_NEW_FEATURES = True\n",
    "TRAIN_SVM = False\n",
    "TRAIN_RF = False\n",
    "\n",
    "MLP_MODEL_PATH = './mlp_regressor.pth'\n",
    "LOAD_MLP_MODEL = False\n",
    "SAVE_MLP_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.read_csv('./full_node_Table_.csv')\n",
    "df = pd.read_csv('./full_Table_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc_df = df.sample(n=1000, random_state=1)\n",
    "cc_df = df\n",
    "cc_df['cc_pixel_intensity_488'] = cc_df['cc_pixel_intensity_488'].astype(int)\n",
    "\n",
    "X = cc_df.drop(['cc_pixel_intensity_488', 'cc_pixel_intensity_405', 'cc_x', 'folder_name_x', 'degree_distribution', 'folder_name_x.1', 'folder_name_y', 'x_y', 'y_y', 'z_y', 'node', 'degree', 'cc_y', 'vol_cc', 'avg_PK_Of_element', 'element_connectivity', 'cc_average_connectivity', 'pixel_intensity_488',\n",
    "'pixel_intensity_405',\n",
    "'pixel_intensity_ratio',\n",
    "'pixel_intensity_555',\n",
    "'element_pixel_intensity_488',\n",
    "'element_pixel_intensity_405',\n",
    "'element_pixel_intensity_ratio'], axis=1)  # Adjust 'target_column' to your actual target column name\n",
    "# Print rows that have NaN in any column, and print that column name\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)\n",
    "\n",
    "# For any rows that contain a NaN in X, drop it in X and drop the corresponding row in Y.\n",
    "# This is done by getting the row index where X is NaN and dropping the same index in both X and Y\n",
    "nan_rows = X.isna().any(axis=1)\n",
    "X = X.dropna()\n",
    "\n",
    "y = cc_df['cc_pixel_intensity_488']\n",
    "y = y[~nan_rows]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "for x in X_train.columns:\n",
    "    print(x)\n",
    "\n",
    "# y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafrac = 1\n",
    "# This cell reads the data from the CSV file and cleans it up\n",
    "\n",
    "if(USE_NEW_FEATURES):\n",
    "\n",
    "    # Set pandas options to display all columns and rows\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    csv_file_path = 'full_Table_All_Cells_With_Angles_And_Edges_CLEANED.csv'\n",
    "    buffer = io.StringIO()\n",
    "\n",
    "    # Open and process the CSV file, to strip entries so that numbers aren't read as strings by read_csv and column names have no leading/trailing whitespaces\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            cleaned_line = ','.join(cell.strip() for cell in line.split(','))\n",
    "            buffer.write(cleaned_line + '\\n')\n",
    "\n",
    "    # Move the buffer cursor to the start\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Read the cleaned data into pandas\n",
    "    data = pd.read_csv(buffer)\n",
    "    edge_columns = [col for col in data.columns if col.startswith('edge_') and col.split('_')[-1].isdigit()]\n",
    "    # Replace empty entries with 0 in these columns\n",
    "    data[edge_columns] = data[edge_columns].fillna(0)\n",
    "\n",
    "    # Not sure if these folder names are required for segregating the dataset, so for now dropping them\n",
    "    data = data.drop(columns=['folder_name_x', 'folder_name_x.1', 'folder_name_y'])\n",
    "    # For now, we aren't using the 555 channel either\n",
    "    data = data.drop(columns=['element_pixel_intensity_555'])\n",
    "\n",
    "    # These fields seem to be not implemented either:\n",
    "    data = data.drop(columns=[\"Unnamed: 0_x\", \"x\", \"y\" ,\"z\" ,\"node_x\" ,\"degree_x\" ,\"vol_cc_x\" ,\"avg_PK_Of_element_x\" ,\"element_connectivity_x\" ,\"Unnamed: 0_y\"])\n",
    "\n",
    "    # The next few lines of code are to convert the degree_distribution column to columns labelled node_degree_0, node_degree_1, etc. till node_degree_MAX\n",
    "    def str_to_dict(s):\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except ValueError:\n",
    "            return {}\n",
    "    # Apply the function to the 'degree_distribution' column\n",
    "    data['degree_distribution'] = data['degree_distribution'].apply(str_to_dict)\n",
    "        \n",
    "    # Find the highest node degree in the DataFrame\n",
    "    max_degree = max(degree for row in data['degree_distribution'] for degree in row.keys())\n",
    "\n",
    "    # Create a DataFrame for new columns\n",
    "    new_columns = pd.DataFrame({f'node_degree_{i}': 0 for i in range(1, max_degree + 1)}, index=data.index)\n",
    "\n",
    "    # Concatenate with the original DataFrame\n",
    "    data = pd.concat([data, new_columns], axis=1)\n",
    "        \n",
    "    # Function to update the degree columns for a row\n",
    "    def update_degrees(row):\n",
    "        for degree, count in row['degree_distribution'].items():\n",
    "            row[f'node_degree_{degree}'] = count\n",
    "        return row\n",
    "\n",
    "    # Apply the function to each row\n",
    "    data = data.apply(update_degrees, axis=1)\n",
    "    data = data.drop(columns=['degree_distribution'])\n",
    "    # Now we should have columns labelled node_degree_0, node_degree_1, etc. till node_degree_MAX and dropped the degree_distribution column\n",
    "\n",
    "    non_numerical_columns = data.select_dtypes(exclude=['int', 'float', 'double']).columns\n",
    "    # Print the non-numerical column names\n",
    "    if(len(non_numerical_columns) > 0):\n",
    "        print(non_numerical_columns)\n",
    "        raise Exception('Non-numerical columns found in dataset, can\\'t train model on it directly')\n",
    "\n",
    "    data['cc_average_connectivity'] = data['cc_average_connectivity'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # Print any columns with values like infinity\n",
    "    columns_with_infinity = data.columns.to_series()[data.apply(lambda x: np.isinf(x).any())]\n",
    "    if(len(columns_with_infinity) > 0):\n",
    "        print(columns_with_infinity)\n",
    "        raise Exception('Columns with infinity values found in dataset, can\\'t train model on it directly')\n",
    "\n",
    "    # Drop rows that have NaN values in columns 'clustering coefficient', 'pixel_intensity_ratio', 'vol_cc_y', 'x_y', 'y_y', 'z_y'\n",
    "    # data = data.dropna(subset=['clustering coefficient', 'pixel_intensity_ratio', 'vol_cc_y', 'x_y', 'y_y', 'z_y'])\n",
    "\n",
    "    # Replace any remaining NaN's with 0\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    columns_with_NaN = data.columns.to_series()[data.apply(lambda x: np.isnan(x).any())]\n",
    "    if(len(columns_with_NaN) > 0):\n",
    "        print(columns_with_NaN.values)\n",
    "        raise Exception('Columns with NaN values found in dataset, can\\'t train model on it directly')\n",
    "\n",
    "    # Train on small subset of data to see if it works first\n",
    "    sample_data = data.sample(frac=datafrac ,random_state=1049)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X = sample_data.drop(columns=['element_pixel_intensity_488'])\n",
    "    X = X.drop(['cc_pixel_intensity_488',\n",
    "                'cc_pixel_intensity_405',\n",
    "                'cc_x', 'x_y', 'y_y', 'z_y', 'cc_y',\n",
    "                'pixel_intensity_405',\n",
    "                'pixel_intensity_ratio',\n",
    "                # 'pixel_intensity_555',\n",
    "                'element_pixel_intensity_405',\n",
    "                'element_pixel_intensity_ratio',\n",
    "                'cc_average_connectivity',\n",
    "                # 'cc_pixel_intensity_555',\n",
    "                'cc_pixel_intensity_ratio', \n",
    "                'pixel_intensity',\n",
    "                'pixel_intensity_488'], axis=1)\n",
    "    \n",
    "    xlabels = X.columns\n",
    "    with open(\"training_feature_list_excl_angles_and_edges.txt\", \"w\") as file:\n",
    "        for thing in xlabels:\n",
    "            if \"Angle\" not in thing and \"edge\" not in thing:\n",
    "                file.write(thing + \"\\n\")\n",
    "    \n",
    "    sample_data['element_pixel_intensity_405_488_ratio'] = (np.array(sample_data['element_pixel_intensity_405']) / np.array(sample_data['element_pixel_intensity_488']))*1000\n",
    "    sample_data.fillna(0, inplace=True)\n",
    "    \n",
    "    # We're basically predicting\n",
    "    # (405 / 488) * 1000\n",
    "\n",
    "    Y = sample_data['element_pixel_intensity_405_488_ratio']\n",
    "    # Group all Y values into classes of 50\n",
    "    # Y = np.floor(Y / 50) * 50\n",
    "\n",
    "    # Perform standardization on X and Y\n",
    "    scalerX = StandardScaler()\n",
    "    scalerY = StandardScaler()\n",
    "\n",
    "    # X = scalerX.fit_transform(X)\n",
    "    # Y = scalerY.fit_transform(Y.values.reshape(-1, 1))\n",
    "    y = np.rint(Y).astype(int)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # y_train, y_test = y_train.reshape(-1), y_test.reshape(-1)\n",
    "    print(\"The training data shapes are:\", X_train.shape, y_train.shape, \"and the testing data shapes are:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_frequency(y_pred, y_test, classifier_title, rounding):\n",
    "    rounding_ = rounding//2\n",
    "    \n",
    "    # Calculate errors\n",
    "    errors = (abs(y_pred - y_test) < rounding_)\n",
    "\n",
    "    # Extract labels where errors occurred\n",
    "    error_labels = y_test[errors]\n",
    "\n",
    "    # Calculate frequency of each label\n",
    "    unique_labels, counts = np.unique(error_labels, return_counts=True)\n",
    "\n",
    "    # Creating a dictionary of label frequencies for errors\n",
    "    label_error_frequency = dict(zip(unique_labels, counts))\n",
    "\n",
    "    # Finding the range of all possible labels (from min to max in y_test and y_pred)\n",
    "    all_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "    min_label = min(all_labels)\n",
    "    max_label = max(all_labels)\n",
    "\n",
    "    # Filling in frequencies for labels that did not have errors\n",
    "    for label in range(min_label, max_label + 1):\n",
    "        if label not in label_error_frequency:\n",
    "            label_error_frequency[label] = 0\n",
    "\n",
    "    # Sorting the dictionary for plotting\n",
    "    sorted_label_error_frequency = dict(sorted(label_error_frequency.items()))\n",
    "\n",
    "    xticks = np.arange(min_label, max_label + 1, 50)\n",
    "\n",
    "    # Plotting the error frequency\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(sorted_label_error_frequency.keys(), sorted_label_error_frequency.values())\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Error Frequency')\n",
    "    plt.title('Error Frequency Distribution for ' + str(classifier_title) + ' for errors >= {} ({} in either direction)'.format(rounding, rounding_))\n",
    "    plt.xticks(xticks, rotation='vertical')  # Set x-ticks to show every 50th label and rotate them vertically\n",
    "    plt.show()\n",
    "\n",
    "    # Calculating mean and standard deviation of absolute errors\n",
    "    absolute_errors = np.abs(y_pred - y_test)\n",
    "    mean_error = np.mean(absolute_errors)\n",
    "    std_error = np.std(absolute_errors)\n",
    "    print(\"The mean error is\", mean_error, \"and the standard deviation of the errors is\", std_error)\n",
    "\n",
    "    # Plotting absolute error for each label\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for label in all_labels:\n",
    "        label_errors = absolute_errors[y_test == label]\n",
    "        plt.bar([label]*len(label_errors), label_errors, color='r')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Absolute Error')\n",
    "    plt.title('Absolute Error for Each Label in ' + str(classifier_title))\n",
    "    plt.xticks(xticks, rotation='vertical')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For y_train and y_test, round down to nearest 10\n",
    "# y_train = (np.floor(y_train / 10) * 10).astype(int)\n",
    "# y_test = (np.floor(y_test / 10) * 10).astype(int)\n",
    "\n",
    "# Noticed weird behaviour with SVM:\n",
    "# If y_train and y_test are not rounded down to nearest 10,\n",
    "# then the training takes LONGER (it just wouldn't finish training on my mac)\n",
    "# even though it means there are 10 times fewer classifiers to train?\n",
    "# (also yes, doing that means the output would not be a regression but a classification,\n",
    "# and outputs would be classified into groups of 10, as in the model would tell you whether the\n",
    "# functional parameter is between 0-10, 10-20, 20-30, etc.)\n",
    "\n",
    "# Also it was not possible to get the SVM to train on my MAC for datasets above 10k rows (10k including training and testing split)\n",
    "# Training just never finished if I tried that, even if I left it running overnight.\n",
    "\n",
    "# This makes sense though because with more classes (i.e discrete functional parameter values in this case),\n",
    "# the training time grows quadratically as that many more classifiers need to be trained.\n",
    "\n",
    "# print(y_train, y_test)\n",
    "\n",
    "if(TRAIN_SVM):\n",
    "\n",
    "    svm_model = SVC(kernel='linear')  # You can choose different kernels like 'rbf', 'poly', etc.\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "\n",
    "    print(pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "    plt.plot(y_test, y_pred, 'o')\n",
    "    plt.title('Accuracy: ' + str(accuracy))\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "\n",
    "    y_pred_svm = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(TRAIN_SVM):\n",
    "    plot_error_frequency(y_pred_svm, y_test, 'SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(TRAIN_RF):\n",
    "\n",
    "    # do the same for random forest\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, random_state=0)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    plt.plot(y_test, y_pred, 'o')\n",
    "    plt.title('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "    y_pred_rf = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(TRAIN_RF):\n",
    "    plot_error_frequency(y_pred_rf, y_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Used the plotly library as this is much nicer looking, and the graph is more interactive and works well with Jupyter Notebooks\n",
    "\n",
    "def plot_absolute_error_plotly(y_pred_model1, y_pred_model2, y_test, model_title1, model_title_2):\n",
    "    def calculate_error_frequency(y_pred):\n",
    "        incorrect = y_pred != y_test\n",
    "\n",
    "        unique_predictions, counts = np.unique(y_pred[incorrect], return_counts=True)\n",
    "        error_freq = dict(zip(unique_predictions, counts))\n",
    "\n",
    "        return error_freq\n",
    "\n",
    "    error_freq_svc = calculate_error_frequency(y_pred_model1)\n",
    "    error_freq_rf = calculate_error_frequency(y_pred_model2)\n",
    "\n",
    "    all_labels = np.unique(np.concatenate((y_pred_model1, y_pred_model2)))\n",
    "    all_labels.sort()\n",
    "\n",
    "    svc_freq = [error_freq_svc.get(label, 0) for label in all_labels]\n",
    "    rf_freq = [error_freq_rf.get(label, 0) for label in all_labels]\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name=model_title1, x=all_labels, y=svc_freq),\n",
    "        go.Bar(name=model_title_2, x=all_labels, y=rf_freq)\n",
    "    ])\n",
    "\n",
    "    fig.update_layout(\n",
    "        barmode='group',\n",
    "        title='Prediction Error Frequency',\n",
    "        xaxis_title='Predicted Label',\n",
    "        yaxis_title='Frequency of Incorrect Predictions',\n",
    "        xaxis=dict(type='category')\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_error_label_frequency_plotly(y_pred_model1, y_pred_model2, y_test, model_title1, model_title2):\n",
    "    labels = np.unique(y_test)\n",
    "    errors_svc = [np.sum((y_pred_model1 != y_test) & (y_test == label)) for label in labels]\n",
    "    errors_rf = [np.sum((y_pred_model2 != y_test) & (y_test == label)) for label in labels]\n",
    "\n",
    "    bar_width = max(0.5, 30 / len(labels))\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name=model_title1, x=labels, y=errors_svc, width=bar_width, marker_color='blue', marker_line_color='blue', marker_line_width=1.5, opacity=1),\n",
    "        go.Bar(name=model_title2, x=labels, y=errors_rf, width=bar_width, marker_color='red', marker_line_color='red', marker_line_width=1.5, opacity=1)\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        barmode='group',\n",
    "        title='Error Frequency per Label',\n",
    "        xaxis_title='Labels',\n",
    "        yaxis_title='Number of Errors',\n",
    "        xaxis=dict(tickmode='array', tickvals=labels[::10]),\n",
    "        plot_bgcolor='rgba(255, 255, 255, 1)',\n",
    "        font=dict(\n",
    "            size=12,  # You can adjust the size of the text here for better visibility\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(TRAIN_RF and TRAIN_SVM):\n",
    "    plot_absolute_error_plotly(y_pred_svm, y_pred_rf, y_test, 'SVC', 'Random Forest')\n",
    "    plot_error_label_frequency_plotly(y_pred_svm, y_pred_rf, y_test, 'SVC', 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution\n",
    "# Basically plot the frequency of ocurrence of each value\n",
    "# of the functional parameter in the dataset inputted to the models\n",
    "\n",
    "# This is only plotting the subset in the training set, and not in the entire dataset\n",
    "\n",
    "def plot_data_distribution(y):\n",
    "    # Calculate the frequency of each value in the y_test array\n",
    "    unique_values, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig = go.Figure(data=go.Bar(x=unique_values, y=counts))\n",
    "\n",
    "    # Update the layout for a better visual representation\n",
    "    fig.update_layout(\n",
    "        title='Data Distribution',\n",
    "        xaxis_title='Unique Values',\n",
    "        yaxis_title='Frequency',\n",
    "        xaxis=dict(type='category'),  # Treat unique values as discrete categories\n",
    "        yaxis=dict(title='Frequency'),  # You can also set the range or scale of the y-axis if needed\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    print(\"The mean of the data distribution is\", np.mean(y_train), \"and the standard deviation is\", np.std(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_distribution(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP regressor class\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.fc3 = nn.Linear(hidden_size//2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MLP regressor\n",
    "input_size = X_train.shape[1]\n",
    "# hidden_size = int((X_train.shape[1] + 1) / 2)\n",
    "hidden_size = input_size\n",
    "mlp_regressor = MLPRegressor(input_size, hidden_size).to(device)\n",
    "if(LOAD_MLP_MODEL):\n",
    "    try:\n",
    "        mlp_regressor.load_state_dict(torch.load(MLP_MODEL_PATH))\n",
    "    except Exception as e:\n",
    "        print(\"Couldn't load model\")\n",
    "        print(e)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(mlp_regressor.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "def create_batches(X, Y, batch_size):\n",
    "    num_batches = int(np.ceil(X.shape[0] / batch_size))\n",
    "    batches = []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X[start:end]\n",
    "        Y_batch = Y[start:end]\n",
    "        batches.append((X_batch, Y_batch))\n",
    "\n",
    "    return batches\n",
    "\n",
    "# Train the MLP regressor\n",
    "def train_mlp_regressor(epochs, batch_size, X_train, Y_train):\n",
    "    # Convert the training data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "\n",
    "    # Create manual batches\n",
    "    train_batches = create_batches(X_train_tensor, Y_train_tensor, batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, Y_batch in train_batches:\n",
    "            # Move batch to the device\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = mlp_regressor(X_batch)\n",
    "            loss = criterion(outputs, Y_batch)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        \n",
    "def test_mlp_regressor(X_test, Y_test):\n",
    "    # Convert the testing data to PyTorch tensors\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32).squeeze()\n",
    "\n",
    "    # Test the MLP regressor\n",
    "    with torch.no_grad():\n",
    "        outputs = mlp_regressor(X_test_tensor)\n",
    "        loss = criterion(outputs, Y_test_tensor)\n",
    "        print(f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "    # Convert the predictions to a NumPy array\n",
    "    return outputs.cpu().detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not LOAD_MLP_MODEL):\n",
    "    train_mlp_regressor(epochs=1000, batch_size=500, X_train=X_train.values if isinstance(X_train, pd.DataFrame) else X_train, Y_train=np.array(y_train).reshape(-1, 1))\n",
    "# Interrupt this cell whenever it feels like this model has trained enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk\n",
    "if(SAVE_MLP_MODEL):\n",
    "    torch.save(mlp_regressor.state_dict(), MLP_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_test, y_pred, rounding):\n",
    "    y_test = y_test.values\n",
    "    rounding = rounding//2\n",
    "    # print(y_pred)\n",
    "    assert(len(y_test) == len(y_pred))\n",
    "    num_predictions = len(y_test)\n",
    "    num_correct_predictions = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if abs(y_test[i] - y_pred[i]) < rounding:\n",
    "            num_correct_predictions += 1\n",
    "    \n",
    "    return num_correct_predictions/num_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_mlp = test_mlp_regressor(X_test.values if isinstance(X_test, pd.DataFrame) else X_test, np.array(y_test).reshape(-1, 1).squeeze())\n",
    "y_pred_mlp = np.rint(y_pred_mlp).astype(int)\n",
    "\n",
    "rounding_graph = 1\n",
    "rounding = 100\n",
    "\n",
    "plt.plot(np.floor(y_test//rounding_graph) * rounding_graph, np.floor(y_pred_mlp//rounding_graph) * rounding_graph, 'o')\n",
    "# accuracy = accuracy_score(np.floor(y_test//rounding) * rounding, np.floor(y_pred_mlp//rounding) * rounding)\n",
    "accuracy = calculate_accuracy(y_test, y_pred_mlp, rounding)\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Accuracy (prediction error < {}): {}'.format(rounding, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_pred_mlp = test_mlp_regressor(X_train.values if isinstance(X_train, pd.DataFrame) else X_train, np.array(y_train).reshape(-1, 1).squeeze())\n",
    "# y_pred_mlp = np.rint(y_pred_mlp).astype(int)\n",
    "\n",
    "# rounding = 10\n",
    "\n",
    "# plt.plot(np.floor(y_train//rounding) * rounding, np.floor(y_pred_mlp//rounding) * rounding, 'o')\n",
    "# accuracy = accuracy_score(np.floor(y_train//rounding) * rounding, np.floor(y_pred_mlp//rounding) * rounding)\n",
    "\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.title('Accuracy (within nearest {}): {}'.format(rounding, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_frequency(y_pred_mlp, y_test, 'MLP', rounding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the test and pred values\n",
    "df = pd.DataFrame({'Test': y_test, 'Pred': y_pred_mlp})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('mlp_test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
