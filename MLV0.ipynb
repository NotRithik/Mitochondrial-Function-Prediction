{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "First, create a graph representation of the information we have. \n",
    "This would be information about the elements, and the nodes. \n",
    "Using this, we will feed it into our SVM, or a Random Forest, and see from there onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generate_Excel import *\n",
    "from MitoCode_Functions import open_file_dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import igraph as ig\n",
    "\n",
    "def Mitograph_Graph(FileName):\n",
    "    # Read information from the gnet file, and create a graph object\n",
    "    # generate a function that takes in the filename and gives out the graph\n",
    "    G = pd.read_table(FileName + '.gnet', skiprows=1, sep='\\t', names=['Source', 'Target', 'Length'])\n",
    "    graph = ig.Graph.TupleList(G.itertuples(index=False), directed=False, edge_attrs=['Length'])\n",
    "    layout = graph.layout_auto()  # Automatic layout calculation\n",
    "    graph.vs['degree'] = graph.degree()\n",
    "    # ig.plot(graph, layout=layout)\n",
    "    Vol = pd.read_table(FileName + '.cc', skiprows=0, sep='\\t')\n",
    "    Vol.columns = ['node', 'cc', 'vol_cc']\n",
    "\n",
    "    ids = [int(node['name']) for node in graph.vs]\n",
    "    graph.vs['cc_vol'] = [Vol.loc[Vol['node'] == node, 'vol_cc'].values[0] for node in ids]\n",
    "    graph.vs['cc'] = [Vol.loc[Vol['node'] == node, 'cc'].values[0] for node in ids]\n",
    "    return graph, Vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = pd.read_csv('/home/mitosim2/Desktop/czi_files/full_node_Table_.csv')\n",
    "# df = pd.read_csv('/home/mitosim2/Desktop/czi_files/full_Table_.csv')\n",
    "n = pd.read_csv('/Users/birat/Onedrive/Desktop/TCDD11S/full_Table_.csv')\n",
    "df = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = df[['cc_x', 'folder_name_x', 'cc_pixel_intensity_488', 'cc_pixel_intensity_405', 'cc_pixel_intensity_555', 'cc_pixel_intensity_ratio', \n",
    "            'cc_average_degree_excludeFreeEnds',\n",
    "             'cc_max_PK', 'diameter', 'cc_vol_from_img_(um3)', 'branches'\n",
    "            , 'nodes', 'edges']].drop_duplicates(subset = ['cc_x','folder_name_x'])\n",
    "\n",
    "# add Percentage Length\n",
    "# average edge length\n",
    "# Max edge length \n",
    "# Min edge length \n",
    "# CV of the edge length \n",
    "# Average PK \n",
    "\n",
    "import warnings\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_cc(main_df, df_dir, title = ''):\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    # plt.clf()\n",
    "    cc_df = main_df[['folder_name_x','cc_x', 'cc_length_(um)', 'cc_max_PK', 'cc_vol_from_img_(um3)', 'branches', 'nodes', 'edges','cc_pixel_intensity_405', 'cc_pixel_intensity_488', 'cc_pixel_intensity_ratio', 'cc_average_degree_excludeFreeEnds', 'diameter', 'cc_average_connectivity']].drop_duplicates()\n",
    "    \n",
    "    cc_df['nodes_per_length'] = cc_df['nodes'] / cc_df['cc_length_(um)']\n",
    "    cc_df['edges_per_length'] = cc_df['edges'] / cc_df['cc_length_(um)']\n",
    "    cc_df['avgdegreeperl'] = cc_df['cc_average_degree_excludeFreeEnds']/cc_df['cc_length_(um)']\n",
    "    cc_df['avgpkperl'] = cc_df['cc_max_PK']/cc_df['cc_length_(um)']\n",
    "    cc_df['average_edge_length'] = cc_df\n",
    "    # cc_df = cc_df[cc_df['edges'] != 1]\n",
    "    a = cc_df.groupby(\"folder_name_x\")\n",
    "    dataframelist = [group for _, group in a]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 7, figsize=(33.6, 4))\n",
    "    \n",
    "    fig.tight_layout(w_pad=2)\n",
    "    colors = cm.tab20(np.linspace(0, 1, len(dataframelist)))\n",
    "    i = -1\n",
    "    for df_index, df in enumerate(dataframelist):\n",
    "        edges = main_df[main_df['cc_x'] == df['cc_x'].values[0] and main_df['folder_name_x'] == df['folder_name_x'].values[0]]\n",
    "        df['average_edge_length'] = edges['element_'].mean() \n",
    "        \n",
    "        # ax.scatter(dat[:, 1], (datfunc),  color=colors[df_index])\n",
    "        # print(len(df['cc_length_(um)']), len(df['cc_pixel_intensity_488']))\n",
    "        # print(type(df['cc_length_(um)']), type(df['cc_pixel_intensity_488']))\n",
    "        # # drop nan values from df \n",
    "        # # df = df.dropna()\n",
    "        # print(len(df['cc_length_(um)']), len(df['cc_pixel_intensity_488']))\n",
    "        ax[0].scatter(df['cc_length_(um)'] ,df['cc_pixel_intensity_ratio'],color=colors[df_index], label=df['folder_name_x'].values[0].split('hr', 1)[-1], s= 12)\n",
    "        ax[1].scatter(df['nodes'],df['cc_pixel_intensity_ratio'],  color=colors[df_index], label=df['folder_name_x'].values[0].split('hr', 1)[-1], s= 12)\n",
    "        ax[2].scatter(df['edges'],df['cc_pixel_intensity_ratio'],  color=colors[df_index], label=df['folder_name_x'].values[0].split('hr', 1)[-1], s= 12)\n",
    "        ax[3].scatter(df['nodes_per_length'],df['cc_pixel_intensity_ratio'],  color=colors[df_index], label=df['folder_name_x'].values[0].split('hr', 1)[-1], s= 12)\n",
    "        ax[4].scatter(df['edges_per_length'],df['cc_pixel_intensity_ratio'],  color=colors[df_index], label=df['folder_name_x'].values[0].split('hr', 1)[-1], s= 12)\n",
    "        ax[5].scatter(df['avgdegreeperl'], df['cc_pixel_intensity_ratio'],  color=colors[df_index], label=df['folder_name_x'].values[0].split('hr', 1)[-1], s= 12)\n",
    "        ax[6].scatter(df['avgpkperl'], df['cc_pixel_intensity_ratio'],  color=colors[df_index], label=df['folder_name_x'].values[0].split('hr', 1)[-1], s= 12)\n",
    "\n",
    "    return cc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = df[['cc_x', 'folder_name_x', 'cc_pixel_intensity_488', 'cc_pixel_intensity_405', 'cc_pixel_intensity_555', 'cc_pixel_intensity_ratio', 'cc_average_degree_excludeFreeEnds',\n",
    "             'cc_max_PK', 'diameter', 'cc_vol_from_img_(um3)', 'branches'\n",
    "            , 'nodes', 'edges']].drop_duplicates(subset = ['cc_x','folder_name_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = df[['cc_x', 'folder_name_x', 'cc_pixel_intensity_488', 'cc_pixel_intensity_405', 'cc_pixel_intensity_555', \n",
    "            'cc_pixel_intensity_ratio', 'cc_average_degree_excludeFreeEnds',\n",
    "             'cc_max_PK', 'diameter', 'cc_vol_from_img_(um3)', 'branches'\n",
    "            , 'nodes', 'edges']].drop_duplicates(subset = ['cc_x','folder_name_x'])\n",
    "\n",
    "ele_df = df[['line_id', 'folder_name_x', 'element_pixel_intensity_488', 'element_pixel_intensity_405', 'element_pixel_intensity_555', \n",
    "            'element_pixel_intensity_ratio', 'element_Volume_Voxel', 'element_length_(um)', 'element_average_width' ]].drop_duplicates(subset=['line_id', 'folder_name_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_df.drop(['line_id', 'folder_name_x', 'element_pixel_intensity_555'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_corr = ele_df.drop(['line_id', 'folder_name_x', 'element_pixel_intensity_555'], axis = 1).corr()\n",
    "ele_corr.to_csv('element_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_corr = cc_df.drop(['cc_x', 'folder_name_x'], axis = 1).corr()\n",
    "cc_corr.to_csv('cc_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eledf = df[['line_id', 'cc_x', 'element_Volume_Voxel', 'element_pixel_intensity_405', 'element_length_(um)', 'element_pixel_intensity_488', 'element_pixel_intensity_555' \n",
    "            ,'element_pixel_intensity_ratio', 'element_average_width', 'folder_name_x']].drop_duplicates(subset=['line_id', 'folder_name_x'])\n",
    "\n",
    "bigDf = n\n",
    "# rename folder_name_x to folder_name in eledf\n",
    "# eledf.rename(columns={'folder_name_x': 'folder_name'}, inplace=True)\n",
    "bigDf = pd.merge(bigDf, eledf, how='left', left_on=['line_id', 'folder_name'], right_on=['line_id', 'folder_name_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigDf = bigDf[['line_id', 'folder_name_x', 'node', 'node_2', 'element_pixel_intensity_488', 'element_pixel_intensity_405', 'element_pixel_intensity_555', 'element_length_(um)', 'element_average_width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = df.drop_duplicates(subset=['cc_x', 'folder_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['folder_name_x', 'line_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('cc_pixel_intensity_488', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ig.Graph.TupleList(bigDf.itertuples(index=False), directed=False, edge_attrs=['line_id', 'element_pixel_intensity_ratio', 'element_pixel_intensity_405', 'element_length_(um)', 'element_pixel_intensity_488'])\n",
    "\n",
    "# ids = [int(node['name']) for node in graph.vs]\n",
    "# graph.vs['cc_vol'] = [df.loc[df['node'] == node, 'degree'].values[0] for node in ids]\n",
    "# graph.vs['488'] = [df.loc[df['node'] == node, 'pixel_intensity_488'].values[0] for node in ids]\n",
    "# graph.vs['405'] = [df.loc[df['node'] == node, 'pixel_intensity_405'].values[0] for node in ids]\n",
    "# graph.vs['ratio'] = [df.loc[df['node'] == node, 'pixel_intensity_ratio'].values[0] for node in ids]\n",
    "# graph.vs['structural'] = [df.loc[df['node'] == node, 'pixel_intensity_555'].values[0] for node in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['line_id', 'folder_name_x', 'cc_x'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.read_csv('/home/mitosim2/Desktop/czi_files/full_node_Table_.csv')\n",
    "df = pd.read_csv('/home/mitosim2/Desktop/czi_files/full_Table_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = df[['cc_x', 'folder_name_x', 'cc_pixel_intensity_488', 'cc_pixel_intensity_405', 'cc_pixel_intensity_ratio',\n",
    "            'cc_pixel_intensity_555',  'cc_average_degree_excludeFreeEnds',\n",
    "             'cc_max_PK', 'diameter', 'cc_vol_from_img_(um3)', 'branches'\n",
    "            , 'nodes', 'edges']].drop_duplicates(subset = ['cc_x','folder_name_x'])\n",
    "\n",
    "ele_df = df[['line_id', 'folder_name_x', 'element_pixel_intensity_488', 'element_pixel_intensity_405', 'element_pixel_intensity_555', \n",
    "            'element_pixel_intensity_ratio', 'element_Volume_Voxel', 'element_length_(um)', 'element_average_width' ]].drop_duplicates(subset=['line_id', 'folder_name_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make cc_df only the first 1000 entries \n",
    "cc_df = cc_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df['cc_pixel_intensity_488'] = cc_df['cc_pixel_intensity_488'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cc_df.drop(['cc_pixel_intensity_488', 'cc_pixel_intensity_405', 'cc_x', 'folder_name_x'], axis=1)  # Adjust 'target_column' to your actual target column name\n",
    "y = cc_df['cc_pixel_intensity_488']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "svm_model = SVC(kernel='linear')  # You can choose different kernels like 'rbf', 'poly', etc.\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "plt.plot(y_test, y_pred, 'o')\n",
    "plt.title('Accuracy: {}'.format(accuracy))\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('test')\n",
    "plt.ylabel('pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_df = ele_df[:1000]\n",
    "ele_df['element_pixel_intensity_488'] = ele_df['element_pixel_intensity_488'].astype(int)\n",
    "\n",
    "X = ele_df.drop(['element_pixel_intensity_405', 'line_id', 'folder_name_x', 'element_pixel_intensity_488', 'element_pixel_intensity_ratio'], axis=1)  # Adjust 'target_column' to your actual target column name\n",
    "y = ele_df['element_pixel_intensity_488']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm_model = SVC(kernel='linear')  # You can choose different kernels like 'rbf', 'poly', etc.\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "plt.plot(y_test, y_pred, 'o')\n",
    "plt.title('Accuracy: {}'.format(accuracy))\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "plt.plot(y_test, y_pred, 'o')\n",
    "plt.title('Accuracy: {}'.format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRepeats(x):\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == x[i+1]:\n",
    "            if i < len(x)-2:\n",
    "                return 1 + findRepeats(x[i+1:])\n",
    "            \n",
    "    return 0\n",
    "\n",
    "findRepeats('abababab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-b \n",
    "def giveKlist(X, k): \n",
    "    nlist = []\n",
    "    indexes_to_add = len(X)//k \n",
    "    for i in range(1, indexes_to_add+1):\n",
    "        nlist.append(X[i*k-1])\n",
    "    return nlist\n",
    "\n",
    "giveKlist([1, 2, 3, 4, 5], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-c \n",
    "def convertBase(val, k): \n",
    "    # get val in base 1: \n",
    "    base1 = val * 10 \n",
    "    # convert base1 to base k\n",
    "    for i in range(0, 10): \n",
    "        if base1 < i**k: \n",
    "            break\n",
    "    return i\n",
    "convertBase(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-d \n",
    "import random \n",
    "def tossCoins(p, t): \n",
    "    # p is probability of heads \n",
    "    # t is number of tosses\n",
    "    resultList = []\n",
    "    for i in range(0, t): \n",
    "        if random.random() < p: \n",
    "            resultList.append('H')\n",
    "        else: \n",
    "            resultList.append('T')\n",
    "    return resultList\n",
    "tossCoins(0.7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-e\n",
    "def printArr(A, B): \n",
    "    len1 = len(A)\n",
    "    len2 = len(B)\n",
    "    longer_len = max(len1, len2)\n",
    "    smaller_len = min(len1, len2)\n",
    "    npList = []\n",
    "    for i in range(0, smaller_len): \n",
    "        npList.append(A[i])\n",
    "        npList.append(B[i])\n",
    "    if len1 > len2: \n",
    "        for i in range(smaller_len, longer_len): \n",
    "            npList.append(A[i])\n",
    "    else:\n",
    "        for i in range(smaller_len, longer_len): \n",
    "            npList.append(B[i])\n",
    "\n",
    "    return npList        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-f\n",
    "def printMany(x, k): \n",
    "    # turn int into string  \n",
    "    x = str(x)\n",
    "    return k * x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-g\n",
    "def reverseString(x): \n",
    "    return x[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-h\n",
    "\n",
    "def reverseSkipNum(x):\n",
    "    # find index position of the numbers\n",
    "    indexes = []\n",
    "    for i in range(len(x)): \n",
    "        if x[i].isdigit(): \n",
    "            indexes.append(i)\n",
    "    print(indexes)\n",
    "    newstr = ''\n",
    "    # remove the numbers from the string\n",
    "    for i in range(len(x)): \n",
    "        if i not in indexes: \n",
    "            newstr += x[i]\n",
    "    # reverse newstr: \n",
    "    newstr = newstr[::-1]\n",
    "    print(newstr)\n",
    "    neweststr = ''\n",
    "    k = 0\n",
    "    for i in range(len(x)): \n",
    "        if i in indexes:\n",
    "            neweststr += x[i]\n",
    "        else: \n",
    "            neweststr += newstr[k]\n",
    "            k = k + 1\n",
    "    return neweststr\n",
    "reverseSkipNum('a1b2c3d4e5f6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonicSum(n):\n",
    "    sum = 0\n",
    "    for i in range(1, n+1): \n",
    "        sum += 1/i\n",
    "    return sum\n",
    "\n",
    "def inverseAdd(x, y): \n",
    "    return harmonicSum(x)/harmonicSum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '1a3rf35'\n",
    "# split string at int\n",
    "intList = []\n",
    "for i in a: \n",
    "    if type(i) == int: \n",
    "        intList.append(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
